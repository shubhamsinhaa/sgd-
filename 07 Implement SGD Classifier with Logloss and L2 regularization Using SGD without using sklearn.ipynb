{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression_using_SGD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I2S-uFqwSvmg",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FUxLkBjISvmr",
        "colab": {}
      },
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xexp5GYNSvmz",
        "outputId": "57a85130-926d-417e-d246-f7d02af37c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pKAn1-ASvm_",
        "outputId": "01cc472a-ff02-4104-f7f7-5bcb09feee12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sShoMeocSvnP",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gm6wi8L2SvnU",
        "outputId": "9e8903fe-22f7-4d2e-b3b2-9fbf2737a81b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q4WFoxgASvnc",
        "outputId": "f6ad2e2e-825a-4136-f366-3d295d00da8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "clf.fit(X=X_train, y=y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.13 seconds.\n",
            "Convergence after 10 epochs took 0.13 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7WaVxhGpSvnj",
        "outputId": "4b6db707-8a03-46c1-fb8d-1dadcff34a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UOBvEchCSvnr"
      },
      "source": [
        "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xbn61rrXSvnt"
      },
      "source": [
        "### Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "14bA5yR3Svnv"
      },
      "source": [
        "- Load the datasets(train and test) into the respective arrays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c7183hFBSvnv"
      },
      "source": [
        "- Initialize the weight_vector and intercept term randomly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hdLeFU0USvnx"
      },
      "source": [
        "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pEVtAlO1Svny"
      },
      "source": [
        "- for each epoch:\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
        "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
        "        $b^{(t+1)} ← (1 − \\frac{αλ}{N} )b^{(t)} + α(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
        "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2qmRH4UpSvny"
      },
      "source": [
        "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lbZf9p5gSvn1"
      },
      "source": [
        "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fpz8X5DMSvn2",
        "outputId": "602b2dd5-c97c-4c86-9c4c-f5a5b6d74039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "w = np.zeros_like(X_train[0])\n",
        "b = 0\n",
        "N = len(X_train)\n",
        "N"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6Y5kVscSvn5",
        "colab": {}
      },
      "source": [
        "# write your code to implement SGD as per the above instructions\n",
        "# please choose the number of iternations on your own"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX6awyt6Nhd5",
        "colab_type": "code",
        "outputId": "80312653-c947-4b4b-beed-d7addccf322c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tqdm import tqdm \n",
        "def sigmoid(w,x,b):\n",
        "    return 1/(1+np.exp(-(np.dot(x,w)+b)))\n",
        "\n",
        "def coefficients_SGD(x_train,x_test,y_train,y_test,n_epoch):\n",
        "    coef=np.random.normal(0,0.0001, size=(len(x_train[0])))\n",
        "    intcpt=np.random.normal(0,0.0001)\n",
        "    lamda  = 0.0001\n",
        "    alpha = 0.0001\n",
        "    N=len(X_train)\n",
        "    LOSS_TRAIN=[]\n",
        "    LOSS_TEST=[]\n",
        "    for epoch in range(n_epoch):\n",
        "        for i in range(len(x_train)):\n",
        "            dcoef= (x_train[i]*(y_train[i]-sigmoid(coef,x_train[i],intcpt)))\n",
        "            dintcpt=(y_train[i]-sigmoid(coef,x_train[i],intcpt))\n",
        "            coef=((1-(alpha*lamda)/N)*coef+(alpha*dcoef))\n",
        "            intcpt=((1-(alpha*lamda)/N)*intcpt+(alpha*dintcpt))\n",
        "        ypred_train= sigmoid(coef,x_train,intcpt)\n",
        "        ypred_test= sigmoid(coef,x_test,intcpt)\n",
        "        loss_train=0\n",
        "        for i in range(len(y_train)):\n",
        "                loss_train=-((y_train[i]*(math.log(ypred_train[i])))+ ((1-y_train[i])*(math.log(1-ypred_train[i]))))\n",
        "        for j in range(len(y_test)):\n",
        "                loss_test=-((y_test[j]*(math.log(ypred_test[j])))+ ((1-y_test[j])*(math.log(1-ypred_test[j])))) \n",
        "        Avg_Loss_Train=loss_train/len(y_train)\n",
        "        LOSS_TRAIN.append(Avg_Loss_Train)\n",
        "        Avg_Loss_Test=loss_test/len(y_test)\n",
        "        LOSS_TEST.append(Avg_Loss_Test)\n",
        "        print(\"epoch=\",epoch,\"; Loss_Train:\",Avg_Loss_Train,\"Loss_Test\",Avg_Loss_Test)\n",
        "    return coef,intcpt,LOSS_TRAIN,LOSS_TEST\n",
        "\n",
        "coef,intcpt,LOSS_TRAIN,LOSS_TEST=coefficients_SGD(X_train,X_test,y_train,y_test,70)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch= 0 ; Loss_Train: 1.769437805454955e-05 Loss_Test 9.808950018400935e-05\n",
            "epoch= 1 ; Loss_Train: 1.6894228719028168e-05 Loss_Test 9.586387328161591e-05\n",
            "epoch= 2 ; Loss_Train: 1.6681175908754043e-05 Loss_Test 9.093702056916448e-05\n",
            "epoch= 3 ; Loss_Train: 1.6588884676066017e-05 Loss_Test 8.693895116322342e-05\n",
            "epoch= 4 ; Loss_Train: 1.6532651381600616e-05 Loss_Test 8.401673286368027e-05\n",
            "epoch= 5 ; Loss_Train: 1.649259273945252e-05 Loss_Test 8.191369177276093e-05\n",
            "epoch= 6 ; Loss_Train: 1.6462683164730193e-05 Loss_Test 8.039381315481112e-05\n",
            "epoch= 7 ; Loss_Train: 1.6440155596316022e-05 Loss_Test 7.928638201835448e-05\n",
            "epoch= 8 ; Loss_Train: 1.642320591185144e-05 Loss_Test 7.847309226199616e-05\n",
            "epoch= 9 ; Loss_Train: 1.641048215616865e-05 Loss_Test 7.787188617687107e-05\n",
            "epoch= 10 ; Loss_Train: 1.6400944952651492e-05 Loss_Test 7.742514817683682e-05\n",
            "epoch= 11 ; Loss_Train: 1.6393799948667966e-05 Loss_Test 7.709185803734507e-05\n",
            "epoch= 12 ; Loss_Train: 1.6388446011269478e-05 Loss_Test 7.684244228140531e-05\n",
            "epoch= 13 ; Loss_Train: 1.638443158182576e-05 Loss_Test 7.665535663621321e-05\n",
            "epoch= 14 ; Loss_Train: 1.6381418928863623e-05 Loss_Test 7.651477470416802e-05\n",
            "epoch= 15 ; Loss_Train: 1.6379155953243134e-05 Loss_Test 7.640899411453836e-05\n",
            "epoch= 16 ; Loss_Train: 1.6377454549611668e-05 Loss_Test 7.632931782060946e-05\n",
            "epoch= 17 ; Loss_Train: 1.6376174282050712e-05 Loss_Test 7.626925691124889e-05\n",
            "epoch= 18 ; Loss_Train: 1.637521018930952e-05 Loss_Test 7.622395537326634e-05\n",
            "epoch= 19 ; Loss_Train: 1.637448372006908e-05 Loss_Test 7.618977078290113e-05\n",
            "epoch= 20 ; Loss_Train: 1.6373936007316777e-05 Loss_Test 7.6163966181915e-05\n",
            "epoch= 21 ; Loss_Train: 1.6373522877949767e-05 Loss_Test 7.614448221160082e-05\n",
            "epoch= 22 ; Loss_Train: 1.637321114561359e-05 Loss_Test 7.612976775968463e-05\n",
            "epoch= 23 ; Loss_Train: 1.6372975852041367e-05 Loss_Test 7.611865360762913e-05\n",
            "epoch= 24 ; Loss_Train: 1.6372798210204634e-05 Loss_Test 7.611025787802682e-05\n",
            "epoch= 25 ; Loss_Train: 1.637266406774203e-05 Loss_Test 7.610391511566186e-05\n",
            "epoch= 26 ; Loss_Train: 1.637256275693918e-05 Loss_Test 7.609912300076844e-05\n",
            "epoch= 27 ; Loss_Train: 1.637248623260413e-05 Loss_Test 7.609550225638775e-05\n",
            "epoch= 28 ; Loss_Train: 1.6372428424822147e-05 Loss_Test 7.60927664515737e-05\n",
            "epoch= 29 ; Loss_Train: 1.6372384752444303e-05 Loss_Test 7.609069923985769e-05\n",
            "epoch= 30 ; Loss_Train: 1.6372351757006805e-05 Loss_Test 7.608913719186664e-05\n",
            "epoch= 31 ; Loss_Train: 1.6372326827041008e-05 Loss_Test 7.608795684120171e-05\n",
            "epoch= 32 ; Loss_Train: 1.637230799030489e-05 Loss_Test 7.608706490614462e-05\n",
            "epoch= 33 ; Loss_Train: 1.637229375711531e-05 Loss_Test 7.608639090660879e-05\n",
            "epoch= 34 ; Loss_Train: 1.6372283002160384e-05 Loss_Test 7.608588158848304e-05\n",
            "epoch= 35 ; Loss_Train: 1.6372274875304604e-05 Loss_Test 7.608549671227059e-05\n",
            "epoch= 36 ; Loss_Train: 1.6372268734258508e-05 Loss_Test 7.608520587180433e-05\n",
            "epoch= 37 ; Loss_Train: 1.6372264093737796e-05 Loss_Test 7.608498609088978e-05\n",
            "epoch= 38 ; Loss_Train: 1.6372260587070384e-05 Loss_Test 7.608482000751302e-05\n",
            "epoch= 39 ; Loss_Train: 1.6372257937196953e-05 Loss_Test 7.608469450189905e-05\n",
            "epoch= 40 ; Loss_Train: 1.6372255934764974e-05 Loss_Test 7.60845996598916e-05\n",
            "epoch= 41 ; Loss_Train: 1.6372254421579983e-05 Loss_Test 7.608452798966443e-05\n",
            "epoch= 42 ; Loss_Train: 1.637225327810276e-05 Loss_Test 7.60844738298504e-05\n",
            "epoch= 43 ; Loss_Train: 1.6372252414003255e-05 Loss_Test 7.60844329022932e-05\n",
            "epoch= 44 ; Loss_Train: 1.63722517610213e-05 Loss_Test 7.608440197409236e-05\n",
            "epoch= 45 ; Loss_Train: 1.6372251267576653e-05 Loss_Test 7.608437860221074e-05\n",
            "epoch= 46 ; Loss_Train: 1.637225089469006e-05 Loss_Test 7.608436094050022e-05\n",
            "epoch= 47 ; Loss_Train: 1.637225061290681e-05 Loss_Test 7.608434759385897e-05\n",
            "epoch= 48 ; Loss_Train: 1.6372250399968415e-05 Loss_Test 7.608433750803877e-05\n",
            "epoch= 49 ; Loss_Train: 1.6372250239054906e-05 Loss_Test 7.60843298863618e-05\n",
            "epoch= 50 ; Loss_Train: 1.6372250117455534e-05 Loss_Test 7.60843241267943e-05\n",
            "epoch= 51 ; Loss_Train: 1.637225002556473e-05 Loss_Test 7.608431977438987e-05\n",
            "epoch= 52 ; Loss_Train: 1.6372249956124716e-05 Loss_Test 7.60843164853534e-05\n",
            "epoch= 53 ; Loss_Train: 1.637224990365011e-05 Loss_Test 7.608431399988599e-05\n",
            "epoch= 54 ; Loss_Train: 1.6372249863995903e-05 Loss_Test 7.608431212166075e-05\n",
            "epoch= 55 ; Loss_Train: 1.6372249834030025e-05 Loss_Test 7.608431070231911e-05\n",
            "epoch= 56 ; Loss_Train: 1.6372249811385196e-05 Loss_Test 7.608430962974712e-05\n",
            "epoch= 57 ; Loss_Train: 1.637224979427301e-05 Loss_Test 7.608430881922254e-05\n",
            "epoch= 58 ; Loss_Train: 1.637224978134145e-05 Loss_Test 7.6084308206724e-05\n",
            "epoch= 59 ; Loss_Train: 1.6372249771569545e-05 Loss_Test 7.608430774386908e-05\n",
            "epoch= 60 ; Loss_Train: 1.63722497641849e-05 Loss_Test 7.60843073940977e-05\n",
            "epoch= 61 ; Loss_Train: 1.6372249758604672e-05 Loss_Test 7.608430712978113e-05\n",
            "epoch= 62 ; Loss_Train: 1.6372249754387797e-05 Loss_Test 7.608430693004259e-05\n",
            "epoch= 63 ; Loss_Train: 1.637224975120087e-05 Loss_Test 7.608430677910372e-05\n",
            "epoch= 64 ; Loss_Train: 1.6372249748792832e-05 Loss_Test 7.608430666504149e-05\n",
            "epoch= 65 ; Loss_Train: 1.6372249746973013e-05 Loss_Test 7.608430657884656e-05\n",
            "epoch= 66 ; Loss_Train: 1.6372249745597692e-05 Loss_Test 7.608430651371019e-05\n",
            "epoch= 67 ; Loss_Train: 1.6372249744558582e-05 Loss_Test 7.608430646448771e-05\n",
            "epoch= 68 ; Loss_Train: 1.6372249743773278e-05 Loss_Test 7.60843064272912e-05\n",
            "epoch= 69 ; Loss_Train: 1.63722497431799e-05 Loss_Test 7.608430639918331e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clLt0AtbNhd8",
        "colab_type": "code",
        "outputId": "399bd6d4-481e-4ee6-8557-ee72ed514e21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(\"Coeficients:\",coef)\n",
        "print(\"\\nIntercept=\",intcpt)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coeficients: [-0.42982412  0.19298994 -0.14855936  0.33811969 -0.22124232  0.56989603\n",
            " -0.44517259 -0.08998862  0.22189033  0.1737813   0.19877135 -0.00066692\n",
            " -0.08135564  0.33908197  0.02298398]\n",
            "\n",
            "Intercept= -0.8922526913805908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifXgdqCE2OB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "096e7a8d-eef0-4a5a-b6a7-25934bd9922a"
      },
      "source": [
        "print(coef-clf.coef_)\n",
        "print(\"\\n\",intcpt-clf.intercept_)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-6.45720777e-03  7.51429134e-03  3.09950136e-05 -3.32437632e-03\n",
            "  -1.30556184e-02  9.73024639e-03  7.25223786e-03  4.09950486e-03\n",
            "   1.26171343e-02 -7.05996385e-03  1.71944496e-03 -4.88608062e-03\n",
            "  -1.75194799e-03  5.53949691e-04  3.16768106e-04]]\n",
            "\n",
            " [-0.03911439]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2EXJmj7NheA",
        "colab_type": "text"
      },
      "source": [
        "# Comparison of W & B between SGD Classifier & Custom Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuzdrtJGNheB",
        "colab_type": "text"
      },
      "source": [
        "[[-6.45720777e-03  7.51429134e-03  3.09950136e-05 -3.32437632e-03\n",
        "  -1.30556184e-02  9.73024639e-03  7.25223786e-03  4.09950486e-03\n",
        "   1.26171343e-02 -7.05996385e-03  1.71944496e-03 -4.88608062e-03\n",
        "  -1.75194799e-03  5.53949691e-04  3.16768106e-04]]\n",
        "\n",
        " [-0.03911439]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWSzUX3hNheC",
        "colab_type": "code",
        "outputId": "2e57e49e-796c-4a42-d0e0-50055d5cb830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "error_train=[]\n",
        "error_train.append(LOSS_TRAIN[0])\n",
        "error_train.append(LOSS_TRAIN[24])\n",
        "error_train.append(LOSS_TRAIN[49])\n",
        "\n",
        "error_test=[]\n",
        "error_test.append(LOSS_TEST[0])\n",
        "error_test.append(LOSS_TEST[24])\n",
        "error_test.append(LOSS_TEST[49])\n",
        "\n",
        "\n",
        "epoch=[1,25,50]\n",
        "plt.plot(epoch,error_train, label='Train')\n",
        "plt.plot(epoch,error_test, label='Test')\n",
        "\n",
        "plt.scatter(epoch,error_train)\n",
        "plt.scatter(epoch,error_test)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"ERROR\")\n",
        "plt.title(\"ERROR PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEWCAYAAABWn/G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcKTZfVCSO81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}